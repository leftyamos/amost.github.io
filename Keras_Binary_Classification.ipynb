{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Binary Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "yIFNMDU87EzU",
        "52pcP94i9eVb"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0ILMGh7_h7-",
        "colab_type": "text"
      },
      "source": [
        "https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xc4Y3F77FVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_EphKr37Vz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols = [f'Pattern{x}' for x in range(1,61)]\n",
        "cols.append('Label')\n",
        "\n",
        "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data',names=cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIdOS0ji7306",
        "colab_type": "code",
        "outputId": "40195aff-008e-4601-f212-666c9cf0d6a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pattern1</th>\n",
              "      <th>Pattern2</th>\n",
              "      <th>Pattern3</th>\n",
              "      <th>Pattern4</th>\n",
              "      <th>Pattern5</th>\n",
              "      <th>Pattern6</th>\n",
              "      <th>Pattern7</th>\n",
              "      <th>Pattern8</th>\n",
              "      <th>Pattern9</th>\n",
              "      <th>Pattern10</th>\n",
              "      <th>Pattern11</th>\n",
              "      <th>Pattern12</th>\n",
              "      <th>Pattern13</th>\n",
              "      <th>Pattern14</th>\n",
              "      <th>Pattern15</th>\n",
              "      <th>Pattern16</th>\n",
              "      <th>Pattern17</th>\n",
              "      <th>Pattern18</th>\n",
              "      <th>Pattern19</th>\n",
              "      <th>Pattern20</th>\n",
              "      <th>Pattern21</th>\n",
              "      <th>Pattern22</th>\n",
              "      <th>Pattern23</th>\n",
              "      <th>Pattern24</th>\n",
              "      <th>Pattern25</th>\n",
              "      <th>Pattern26</th>\n",
              "      <th>Pattern27</th>\n",
              "      <th>Pattern28</th>\n",
              "      <th>Pattern29</th>\n",
              "      <th>Pattern30</th>\n",
              "      <th>Pattern31</th>\n",
              "      <th>Pattern32</th>\n",
              "      <th>Pattern33</th>\n",
              "      <th>Pattern34</th>\n",
              "      <th>Pattern35</th>\n",
              "      <th>Pattern36</th>\n",
              "      <th>Pattern37</th>\n",
              "      <th>Pattern38</th>\n",
              "      <th>Pattern39</th>\n",
              "      <th>Pattern40</th>\n",
              "      <th>Pattern41</th>\n",
              "      <th>Pattern42</th>\n",
              "      <th>Pattern43</th>\n",
              "      <th>Pattern44</th>\n",
              "      <th>Pattern45</th>\n",
              "      <th>Pattern46</th>\n",
              "      <th>Pattern47</th>\n",
              "      <th>Pattern48</th>\n",
              "      <th>Pattern49</th>\n",
              "      <th>Pattern50</th>\n",
              "      <th>Pattern51</th>\n",
              "      <th>Pattern52</th>\n",
              "      <th>Pattern53</th>\n",
              "      <th>Pattern54</th>\n",
              "      <th>Pattern55</th>\n",
              "      <th>Pattern56</th>\n",
              "      <th>Pattern57</th>\n",
              "      <th>Pattern58</th>\n",
              "      <th>Pattern59</th>\n",
              "      <th>Pattern60</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.2238</td>\n",
              "      <td>0.0645</td>\n",
              "      <td>0.0660</td>\n",
              "      <td>0.2273</td>\n",
              "      <td>0.3100</td>\n",
              "      <td>0.2999</td>\n",
              "      <td>0.5078</td>\n",
              "      <td>0.4797</td>\n",
              "      <td>0.5783</td>\n",
              "      <td>0.5071</td>\n",
              "      <td>0.4328</td>\n",
              "      <td>0.5550</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.7104</td>\n",
              "      <td>0.8080</td>\n",
              "      <td>0.6791</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>0.1307</td>\n",
              "      <td>0.2604</td>\n",
              "      <td>0.5121</td>\n",
              "      <td>0.7547</td>\n",
              "      <td>0.8537</td>\n",
              "      <td>0.8507</td>\n",
              "      <td>0.6692</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.4943</td>\n",
              "      <td>0.2744</td>\n",
              "      <td>0.0510</td>\n",
              "      <td>0.2834</td>\n",
              "      <td>0.2825</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.2641</td>\n",
              "      <td>0.1386</td>\n",
              "      <td>0.1051</td>\n",
              "      <td>0.1343</td>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0324</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Pattern1  Pattern2  Pattern3  ...  Pattern59  Pattern60  Label\n",
              "0    0.0200    0.0371    0.0428  ...     0.0090     0.0032      R\n",
              "1    0.0453    0.0523    0.0843  ...     0.0052     0.0044      R\n",
              "2    0.0262    0.0582    0.1099  ...     0.0095     0.0078      R\n",
              "3    0.0100    0.0171    0.0623  ...     0.0040     0.0117      R\n",
              "4    0.0762    0.0666    0.0481  ...     0.0107     0.0094      R\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFi507I8-d3z",
        "colab_type": "code",
        "outputId": "4f59d58c-caf1-423d-89ff-f0fdc7039f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 208 entries, 0 to 207\n",
            "Data columns (total 61 columns):\n",
            " #   Column     Non-Null Count  Dtype  \n",
            "---  ------     --------------  -----  \n",
            " 0   Pattern1   208 non-null    float64\n",
            " 1   Pattern2   208 non-null    float64\n",
            " 2   Pattern3   208 non-null    float64\n",
            " 3   Pattern4   208 non-null    float64\n",
            " 4   Pattern5   208 non-null    float64\n",
            " 5   Pattern6   208 non-null    float64\n",
            " 6   Pattern7   208 non-null    float64\n",
            " 7   Pattern8   208 non-null    float64\n",
            " 8   Pattern9   208 non-null    float64\n",
            " 9   Pattern10  208 non-null    float64\n",
            " 10  Pattern11  208 non-null    float64\n",
            " 11  Pattern12  208 non-null    float64\n",
            " 12  Pattern13  208 non-null    float64\n",
            " 13  Pattern14  208 non-null    float64\n",
            " 14  Pattern15  208 non-null    float64\n",
            " 15  Pattern16  208 non-null    float64\n",
            " 16  Pattern17  208 non-null    float64\n",
            " 17  Pattern18  208 non-null    float64\n",
            " 18  Pattern19  208 non-null    float64\n",
            " 19  Pattern20  208 non-null    float64\n",
            " 20  Pattern21  208 non-null    float64\n",
            " 21  Pattern22  208 non-null    float64\n",
            " 22  Pattern23  208 non-null    float64\n",
            " 23  Pattern24  208 non-null    float64\n",
            " 24  Pattern25  208 non-null    float64\n",
            " 25  Pattern26  208 non-null    float64\n",
            " 26  Pattern27  208 non-null    float64\n",
            " 27  Pattern28  208 non-null    float64\n",
            " 28  Pattern29  208 non-null    float64\n",
            " 29  Pattern30  208 non-null    float64\n",
            " 30  Pattern31  208 non-null    float64\n",
            " 31  Pattern32  208 non-null    float64\n",
            " 32  Pattern33  208 non-null    float64\n",
            " 33  Pattern34  208 non-null    float64\n",
            " 34  Pattern35  208 non-null    float64\n",
            " 35  Pattern36  208 non-null    float64\n",
            " 36  Pattern37  208 non-null    float64\n",
            " 37  Pattern38  208 non-null    float64\n",
            " 38  Pattern39  208 non-null    float64\n",
            " 39  Pattern40  208 non-null    float64\n",
            " 40  Pattern41  208 non-null    float64\n",
            " 41  Pattern42  208 non-null    float64\n",
            " 42  Pattern43  208 non-null    float64\n",
            " 43  Pattern44  208 non-null    float64\n",
            " 44  Pattern45  208 non-null    float64\n",
            " 45  Pattern46  208 non-null    float64\n",
            " 46  Pattern47  208 non-null    float64\n",
            " 47  Pattern48  208 non-null    float64\n",
            " 48  Pattern49  208 non-null    float64\n",
            " 49  Pattern50  208 non-null    float64\n",
            " 50  Pattern51  208 non-null    float64\n",
            " 51  Pattern52  208 non-null    float64\n",
            " 52  Pattern53  208 non-null    float64\n",
            " 53  Pattern54  208 non-null    float64\n",
            " 54  Pattern55  208 non-null    float64\n",
            " 55  Pattern56  208 non-null    float64\n",
            " 56  Pattern57  208 non-null    float64\n",
            " 57  Pattern58  208 non-null    float64\n",
            " 58  Pattern59  208 non-null    float64\n",
            " 59  Pattern60  208 non-null    float64\n",
            " 60  Label      208 non-null    object \n",
            "dtypes: float64(60), object(1)\n",
            "memory usage: 99.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6_qlNGUdz0F",
        "colab_type": "code",
        "outputId": "30736d5b-4f97-4f13-976d-38ea0978aa5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "data['Label'].unique()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['R', 'M'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04imI0Nm-x6b",
        "colab_type": "code",
        "outputId": "16235e5c-8f6d-4c59-a0c1-182f77cbfcc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pattern1</th>\n",
              "      <th>Pattern2</th>\n",
              "      <th>Pattern3</th>\n",
              "      <th>Pattern4</th>\n",
              "      <th>Pattern5</th>\n",
              "      <th>Pattern6</th>\n",
              "      <th>Pattern7</th>\n",
              "      <th>Pattern8</th>\n",
              "      <th>Pattern9</th>\n",
              "      <th>Pattern10</th>\n",
              "      <th>Pattern11</th>\n",
              "      <th>Pattern12</th>\n",
              "      <th>Pattern13</th>\n",
              "      <th>Pattern14</th>\n",
              "      <th>Pattern15</th>\n",
              "      <th>Pattern16</th>\n",
              "      <th>Pattern17</th>\n",
              "      <th>Pattern18</th>\n",
              "      <th>Pattern19</th>\n",
              "      <th>Pattern20</th>\n",
              "      <th>Pattern21</th>\n",
              "      <th>Pattern22</th>\n",
              "      <th>Pattern23</th>\n",
              "      <th>Pattern24</th>\n",
              "      <th>Pattern25</th>\n",
              "      <th>Pattern26</th>\n",
              "      <th>Pattern27</th>\n",
              "      <th>Pattern28</th>\n",
              "      <th>Pattern29</th>\n",
              "      <th>Pattern30</th>\n",
              "      <th>Pattern31</th>\n",
              "      <th>Pattern32</th>\n",
              "      <th>Pattern33</th>\n",
              "      <th>Pattern34</th>\n",
              "      <th>Pattern35</th>\n",
              "      <th>Pattern36</th>\n",
              "      <th>Pattern37</th>\n",
              "      <th>Pattern38</th>\n",
              "      <th>Pattern39</th>\n",
              "      <th>Pattern40</th>\n",
              "      <th>Pattern41</th>\n",
              "      <th>Pattern42</th>\n",
              "      <th>Pattern43</th>\n",
              "      <th>Pattern44</th>\n",
              "      <th>Pattern45</th>\n",
              "      <th>Pattern46</th>\n",
              "      <th>Pattern47</th>\n",
              "      <th>Pattern48</th>\n",
              "      <th>Pattern49</th>\n",
              "      <th>Pattern50</th>\n",
              "      <th>Pattern51</th>\n",
              "      <th>Pattern52</th>\n",
              "      <th>Pattern53</th>\n",
              "      <th>Pattern54</th>\n",
              "      <th>Pattern55</th>\n",
              "      <th>Pattern56</th>\n",
              "      <th>Pattern57</th>\n",
              "      <th>Pattern58</th>\n",
              "      <th>Pattern59</th>\n",
              "      <th>Pattern60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>208.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.029164</td>\n",
              "      <td>0.038437</td>\n",
              "      <td>0.043832</td>\n",
              "      <td>0.053892</td>\n",
              "      <td>0.075202</td>\n",
              "      <td>0.104570</td>\n",
              "      <td>0.121747</td>\n",
              "      <td>0.134799</td>\n",
              "      <td>0.178003</td>\n",
              "      <td>0.208259</td>\n",
              "      <td>0.236013</td>\n",
              "      <td>0.250221</td>\n",
              "      <td>0.273305</td>\n",
              "      <td>0.296568</td>\n",
              "      <td>0.320201</td>\n",
              "      <td>0.378487</td>\n",
              "      <td>0.415983</td>\n",
              "      <td>0.452318</td>\n",
              "      <td>0.504812</td>\n",
              "      <td>0.563047</td>\n",
              "      <td>0.609060</td>\n",
              "      <td>0.624275</td>\n",
              "      <td>0.646975</td>\n",
              "      <td>0.672654</td>\n",
              "      <td>0.675424</td>\n",
              "      <td>0.699866</td>\n",
              "      <td>0.702155</td>\n",
              "      <td>0.694024</td>\n",
              "      <td>0.642074</td>\n",
              "      <td>0.580928</td>\n",
              "      <td>0.504475</td>\n",
              "      <td>0.439040</td>\n",
              "      <td>0.417220</td>\n",
              "      <td>0.403233</td>\n",
              "      <td>0.392571</td>\n",
              "      <td>0.384848</td>\n",
              "      <td>0.363807</td>\n",
              "      <td>0.339657</td>\n",
              "      <td>0.325800</td>\n",
              "      <td>0.311207</td>\n",
              "      <td>0.289252</td>\n",
              "      <td>0.278293</td>\n",
              "      <td>0.246542</td>\n",
              "      <td>0.214075</td>\n",
              "      <td>0.197232</td>\n",
              "      <td>0.160631</td>\n",
              "      <td>0.122453</td>\n",
              "      <td>0.091424</td>\n",
              "      <td>0.051929</td>\n",
              "      <td>0.020424</td>\n",
              "      <td>0.016069</td>\n",
              "      <td>0.013420</td>\n",
              "      <td>0.010709</td>\n",
              "      <td>0.010941</td>\n",
              "      <td>0.009290</td>\n",
              "      <td>0.008222</td>\n",
              "      <td>0.007820</td>\n",
              "      <td>0.007949</td>\n",
              "      <td>0.007941</td>\n",
              "      <td>0.006507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.022991</td>\n",
              "      <td>0.032960</td>\n",
              "      <td>0.038428</td>\n",
              "      <td>0.046528</td>\n",
              "      <td>0.055552</td>\n",
              "      <td>0.059105</td>\n",
              "      <td>0.061788</td>\n",
              "      <td>0.085152</td>\n",
              "      <td>0.118387</td>\n",
              "      <td>0.134416</td>\n",
              "      <td>0.132705</td>\n",
              "      <td>0.140072</td>\n",
              "      <td>0.140962</td>\n",
              "      <td>0.164474</td>\n",
              "      <td>0.205427</td>\n",
              "      <td>0.232650</td>\n",
              "      <td>0.263677</td>\n",
              "      <td>0.261529</td>\n",
              "      <td>0.257988</td>\n",
              "      <td>0.262653</td>\n",
              "      <td>0.257818</td>\n",
              "      <td>0.255883</td>\n",
              "      <td>0.250175</td>\n",
              "      <td>0.239116</td>\n",
              "      <td>0.244926</td>\n",
              "      <td>0.237228</td>\n",
              "      <td>0.245657</td>\n",
              "      <td>0.237189</td>\n",
              "      <td>0.240250</td>\n",
              "      <td>0.220749</td>\n",
              "      <td>0.213992</td>\n",
              "      <td>0.213237</td>\n",
              "      <td>0.206513</td>\n",
              "      <td>0.231242</td>\n",
              "      <td>0.259132</td>\n",
              "      <td>0.264121</td>\n",
              "      <td>0.239912</td>\n",
              "      <td>0.212973</td>\n",
              "      <td>0.199075</td>\n",
              "      <td>0.178662</td>\n",
              "      <td>0.171111</td>\n",
              "      <td>0.168728</td>\n",
              "      <td>0.138993</td>\n",
              "      <td>0.133291</td>\n",
              "      <td>0.151628</td>\n",
              "      <td>0.133938</td>\n",
              "      <td>0.086953</td>\n",
              "      <td>0.062417</td>\n",
              "      <td>0.035954</td>\n",
              "      <td>0.013665</td>\n",
              "      <td>0.012008</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>0.007060</td>\n",
              "      <td>0.007301</td>\n",
              "      <td>0.007088</td>\n",
              "      <td>0.005736</td>\n",
              "      <td>0.005785</td>\n",
              "      <td>0.006470</td>\n",
              "      <td>0.006181</td>\n",
              "      <td>0.005031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.011300</td>\n",
              "      <td>0.028900</td>\n",
              "      <td>0.023600</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.034900</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.049400</td>\n",
              "      <td>0.065600</td>\n",
              "      <td>0.051200</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.056300</td>\n",
              "      <td>0.023900</td>\n",
              "      <td>0.024000</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.048100</td>\n",
              "      <td>0.028400</td>\n",
              "      <td>0.014400</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.048200</td>\n",
              "      <td>0.040400</td>\n",
              "      <td>0.047700</td>\n",
              "      <td>0.021200</td>\n",
              "      <td>0.022300</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>0.038300</td>\n",
              "      <td>0.037100</td>\n",
              "      <td>0.011700</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.005600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.013350</td>\n",
              "      <td>0.016450</td>\n",
              "      <td>0.018950</td>\n",
              "      <td>0.024375</td>\n",
              "      <td>0.038050</td>\n",
              "      <td>0.067025</td>\n",
              "      <td>0.080900</td>\n",
              "      <td>0.080425</td>\n",
              "      <td>0.097025</td>\n",
              "      <td>0.111275</td>\n",
              "      <td>0.129250</td>\n",
              "      <td>0.133475</td>\n",
              "      <td>0.166125</td>\n",
              "      <td>0.175175</td>\n",
              "      <td>0.164625</td>\n",
              "      <td>0.196300</td>\n",
              "      <td>0.205850</td>\n",
              "      <td>0.242075</td>\n",
              "      <td>0.299075</td>\n",
              "      <td>0.350625</td>\n",
              "      <td>0.399725</td>\n",
              "      <td>0.406925</td>\n",
              "      <td>0.450225</td>\n",
              "      <td>0.540725</td>\n",
              "      <td>0.525800</td>\n",
              "      <td>0.544175</td>\n",
              "      <td>0.531900</td>\n",
              "      <td>0.534775</td>\n",
              "      <td>0.463700</td>\n",
              "      <td>0.411400</td>\n",
              "      <td>0.345550</td>\n",
              "      <td>0.281400</td>\n",
              "      <td>0.257875</td>\n",
              "      <td>0.217575</td>\n",
              "      <td>0.179375</td>\n",
              "      <td>0.154350</td>\n",
              "      <td>0.160100</td>\n",
              "      <td>0.174275</td>\n",
              "      <td>0.173975</td>\n",
              "      <td>0.186450</td>\n",
              "      <td>0.163100</td>\n",
              "      <td>0.158900</td>\n",
              "      <td>0.155200</td>\n",
              "      <td>0.126875</td>\n",
              "      <td>0.094475</td>\n",
              "      <td>0.068550</td>\n",
              "      <td>0.064250</td>\n",
              "      <td>0.045125</td>\n",
              "      <td>0.026350</td>\n",
              "      <td>0.011550</td>\n",
              "      <td>0.008425</td>\n",
              "      <td>0.007275</td>\n",
              "      <td>0.005075</td>\n",
              "      <td>0.005375</td>\n",
              "      <td>0.004150</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>0.003675</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.022800</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>0.034300</td>\n",
              "      <td>0.044050</td>\n",
              "      <td>0.062500</td>\n",
              "      <td>0.092150</td>\n",
              "      <td>0.106950</td>\n",
              "      <td>0.112100</td>\n",
              "      <td>0.152250</td>\n",
              "      <td>0.182400</td>\n",
              "      <td>0.224800</td>\n",
              "      <td>0.249050</td>\n",
              "      <td>0.263950</td>\n",
              "      <td>0.281100</td>\n",
              "      <td>0.281700</td>\n",
              "      <td>0.304700</td>\n",
              "      <td>0.308400</td>\n",
              "      <td>0.368300</td>\n",
              "      <td>0.434950</td>\n",
              "      <td>0.542500</td>\n",
              "      <td>0.617700</td>\n",
              "      <td>0.664900</td>\n",
              "      <td>0.699700</td>\n",
              "      <td>0.698500</td>\n",
              "      <td>0.721100</td>\n",
              "      <td>0.754500</td>\n",
              "      <td>0.745600</td>\n",
              "      <td>0.731900</td>\n",
              "      <td>0.680800</td>\n",
              "      <td>0.607150</td>\n",
              "      <td>0.490350</td>\n",
              "      <td>0.429600</td>\n",
              "      <td>0.391200</td>\n",
              "      <td>0.351050</td>\n",
              "      <td>0.312750</td>\n",
              "      <td>0.321150</td>\n",
              "      <td>0.306300</td>\n",
              "      <td>0.312700</td>\n",
              "      <td>0.283500</td>\n",
              "      <td>0.278050</td>\n",
              "      <td>0.259500</td>\n",
              "      <td>0.245100</td>\n",
              "      <td>0.222550</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.148000</td>\n",
              "      <td>0.121350</td>\n",
              "      <td>0.101650</td>\n",
              "      <td>0.078100</td>\n",
              "      <td>0.044700</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.013900</td>\n",
              "      <td>0.011400</td>\n",
              "      <td>0.009550</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.006850</td>\n",
              "      <td>0.005950</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.006400</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.035550</td>\n",
              "      <td>0.047950</td>\n",
              "      <td>0.057950</td>\n",
              "      <td>0.064500</td>\n",
              "      <td>0.100275</td>\n",
              "      <td>0.134125</td>\n",
              "      <td>0.154000</td>\n",
              "      <td>0.169600</td>\n",
              "      <td>0.233425</td>\n",
              "      <td>0.268700</td>\n",
              "      <td>0.301650</td>\n",
              "      <td>0.331250</td>\n",
              "      <td>0.351250</td>\n",
              "      <td>0.386175</td>\n",
              "      <td>0.452925</td>\n",
              "      <td>0.535725</td>\n",
              "      <td>0.659425</td>\n",
              "      <td>0.679050</td>\n",
              "      <td>0.731400</td>\n",
              "      <td>0.809325</td>\n",
              "      <td>0.816975</td>\n",
              "      <td>0.831975</td>\n",
              "      <td>0.848575</td>\n",
              "      <td>0.872175</td>\n",
              "      <td>0.873725</td>\n",
              "      <td>0.893800</td>\n",
              "      <td>0.917100</td>\n",
              "      <td>0.900275</td>\n",
              "      <td>0.852125</td>\n",
              "      <td>0.735175</td>\n",
              "      <td>0.641950</td>\n",
              "      <td>0.580300</td>\n",
              "      <td>0.556125</td>\n",
              "      <td>0.596125</td>\n",
              "      <td>0.593350</td>\n",
              "      <td>0.556525</td>\n",
              "      <td>0.518900</td>\n",
              "      <td>0.440550</td>\n",
              "      <td>0.434900</td>\n",
              "      <td>0.424350</td>\n",
              "      <td>0.387525</td>\n",
              "      <td>0.384250</td>\n",
              "      <td>0.324525</td>\n",
              "      <td>0.271750</td>\n",
              "      <td>0.231550</td>\n",
              "      <td>0.200375</td>\n",
              "      <td>0.154425</td>\n",
              "      <td>0.120100</td>\n",
              "      <td>0.068525</td>\n",
              "      <td>0.025275</td>\n",
              "      <td>0.020825</td>\n",
              "      <td>0.016725</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>0.014500</td>\n",
              "      <td>0.012100</td>\n",
              "      <td>0.010575</td>\n",
              "      <td>0.010425</td>\n",
              "      <td>0.010350</td>\n",
              "      <td>0.010325</td>\n",
              "      <td>0.008525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.137100</td>\n",
              "      <td>0.233900</td>\n",
              "      <td>0.305900</td>\n",
              "      <td>0.426400</td>\n",
              "      <td>0.401000</td>\n",
              "      <td>0.382300</td>\n",
              "      <td>0.372900</td>\n",
              "      <td>0.459000</td>\n",
              "      <td>0.682800</td>\n",
              "      <td>0.710600</td>\n",
              "      <td>0.734200</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.713100</td>\n",
              "      <td>0.997000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998800</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.965700</td>\n",
              "      <td>0.930600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.964700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.949700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.985700</td>\n",
              "      <td>0.929700</td>\n",
              "      <td>0.899500</td>\n",
              "      <td>0.824600</td>\n",
              "      <td>0.773300</td>\n",
              "      <td>0.776200</td>\n",
              "      <td>0.703400</td>\n",
              "      <td>0.729200</td>\n",
              "      <td>0.552200</td>\n",
              "      <td>0.333900</td>\n",
              "      <td>0.198100</td>\n",
              "      <td>0.082500</td>\n",
              "      <td>0.100400</td>\n",
              "      <td>0.070900</td>\n",
              "      <td>0.039000</td>\n",
              "      <td>0.035200</td>\n",
              "      <td>0.044700</td>\n",
              "      <td>0.039400</td>\n",
              "      <td>0.035500</td>\n",
              "      <td>0.044000</td>\n",
              "      <td>0.036400</td>\n",
              "      <td>0.043900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Pattern1    Pattern2    Pattern3  ...   Pattern58   Pattern59   Pattern60\n",
              "count  208.000000  208.000000  208.000000  ...  208.000000  208.000000  208.000000\n",
              "mean     0.029164    0.038437    0.043832  ...    0.007949    0.007941    0.006507\n",
              "std      0.022991    0.032960    0.038428  ...    0.006470    0.006181    0.005031\n",
              "min      0.001500    0.000600    0.001500  ...    0.000300    0.000100    0.000600\n",
              "25%      0.013350    0.016450    0.018950  ...    0.003600    0.003675    0.003100\n",
              "50%      0.022800    0.030800    0.034300  ...    0.005800    0.006400    0.005300\n",
              "75%      0.035550    0.047950    0.057950  ...    0.010350    0.010325    0.008525\n",
              "max      0.137100    0.233900    0.305900  ...    0.044000    0.036400    0.043900\n",
              "\n",
              "[8 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LACLHkUI-6WC",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p441O5F1-zsN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = data.drop('Label',axis=1)\n",
        "\n",
        "y = data['Label']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OerxMoM5_L9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode label\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LZYmGEoB2oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "y = le.fit_transform(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z5cYCi7Ha4X",
        "colab_type": "text"
      },
      "source": [
        "## Model 1 : Non-scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc2ddvejB9Wh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1_ArdnM58Tx",
        "colab_type": "text"
      },
      "source": [
        "#### Example method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLfrGWI6Ho4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afakgo4QHu5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baseline model\n",
        "def create_baseline():\n",
        "\n",
        "\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\tmodel.add(Dense(60, input_dim=60, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " \n",
        " \n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0Of-lseH_Eb",
        "colab_type": "code",
        "outputId": "0d1da0c3-3bf5-450d-cdf4-a7692b3c5117",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# evaluate model with standardized dataset\n",
        "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "results = cross_val_score(estimator, x, y, cv=kfold)\n",
        "\n",
        "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline: 81.24% (8.14%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK9NofJt6AK8",
        "colab_type": "text"
      },
      "source": [
        "#### My method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_57wxqr7vZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMsmFHSk7zKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmpHGJRoII-s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Dense(60, input_dim=60, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8F_UcpZWIgYH",
        "colab_type": "code",
        "outputId": "91eba1ea-1cfb-4736-9b17-5293071da6d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x=X_train,\n",
        "          y=y_train,\n",
        "          epochs=100,\n",
        "          batch_size=5,\n",
        "          verbose=1)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.6815 - accuracy: 0.5655\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6069\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.6414\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.6175 - accuracy: 0.6552\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.6089 - accuracy: 0.6690\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.5947 - accuracy: 0.6759\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.5722 - accuracy: 0.7379\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7517\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7448\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.5346 - accuracy: 0.7379\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.5255 - accuracy: 0.7586\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.5130 - accuracy: 0.8000\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.5022 - accuracy: 0.7931\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4916 - accuracy: 0.8000\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.7517\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7793\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.8138\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.8000\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4521 - accuracy: 0.8138\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4481 - accuracy: 0.8000\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4596 - accuracy: 0.7724\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4463 - accuracy: 0.7931\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4260 - accuracy: 0.8000\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4305 - accuracy: 0.8069\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4172 - accuracy: 0.8276\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4333 - accuracy: 0.8138\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4087 - accuracy: 0.8207\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 0.8276\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3995 - accuracy: 0.8345\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4039 - accuracy: 0.8276\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3936 - accuracy: 0.8276\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3876 - accuracy: 0.8207\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3950 - accuracy: 0.8069\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3839 - accuracy: 0.8000\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3937 - accuracy: 0.8138\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3828 - accuracy: 0.8552\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.3681 - accuracy: 0.8138\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3800 - accuracy: 0.8552\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3749 - accuracy: 0.8276\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3597 - accuracy: 0.8276\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3497 - accuracy: 0.8621\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3488 - accuracy: 0.8552\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3483 - accuracy: 0.8345\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3404 - accuracy: 0.8621\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3402 - accuracy: 0.8690\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3440 - accuracy: 0.8828\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8690\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8621\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8690\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3234 - accuracy: 0.8690\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3217 - accuracy: 0.8552\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8690\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3092 - accuracy: 0.8897\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3293 - accuracy: 0.8759\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3118 - accuracy: 0.8828\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8759\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.8552\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2964 - accuracy: 0.8828\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2899 - accuracy: 0.8966\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2930 - accuracy: 0.8759\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2946 - accuracy: 0.9034\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2892 - accuracy: 0.8897\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2871 - accuracy: 0.8828\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2842 - accuracy: 0.8897\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2797 - accuracy: 0.8828\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2779 - accuracy: 0.8966\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2670 - accuracy: 0.8897\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2691 - accuracy: 0.8897\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.2666 - accuracy: 0.8897\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2590 - accuracy: 0.9034\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2654 - accuracy: 0.8828\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2570 - accuracy: 0.8897\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.9103\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2478 - accuracy: 0.9103\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.9034\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2471 - accuracy: 0.8966\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2380 - accuracy: 0.9172\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2479 - accuracy: 0.8897\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2380 - accuracy: 0.9310\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2332 - accuracy: 0.9103\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2355 - accuracy: 0.9241\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2258 - accuracy: 0.9103\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2252 - accuracy: 0.9172\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2170 - accuracy: 0.9310\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2177 - accuracy: 0.9310\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2411 - accuracy: 0.8897\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.9172\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.9034\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2127 - accuracy: 0.9310\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2126 - accuracy: 0.9379\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2053 - accuracy: 0.9379\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2052 - accuracy: 0.9310\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.9379\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2049 - accuracy: 0.9241\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2021 - accuracy: 0.9241\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1970 - accuracy: 0.9379\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2007 - accuracy: 0.9310\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1887 - accuracy: 0.9448\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1859 - accuracy: 0.9448\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1882 - accuracy: 0.9310\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd39a5e9828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c0n75J3IcTP",
        "colab_type": "code",
        "outputId": "73a0ce4e-0ee7-4144-ee49-62a2faea1759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "\n",
        "model_loss.plot()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd39a57e860>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXt40a286G4s",
        "colab_type": "text"
      },
      "source": [
        "## Model 2 : With Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7dbl-C0JMDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# encode features\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pveQcg47Ar7",
        "colab_type": "text"
      },
      "source": [
        "#### Example method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEup0yyt6efh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# create a pipeline\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5BwH1SX6pkx",
        "colab_type": "code",
        "outputId": "9ea24ec8-30a9-4640-e557-63981d681b1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# evaluate baseline model with standardized dataset\n",
        "estimators = []\n",
        "\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)))\n",
        "\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "results = cross_val_score(pipeline, x, y, cv=kfold)\n",
        "\n",
        "print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Standardized: 85.07% (10.70%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIFNMDU87EzU",
        "colab_type": "text"
      },
      "source": [
        "#### My method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFlE9gQa8Rt6",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ce3sXQy8Ruj",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEnqiPWY6ytt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH_4UMo57O9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5-2AeDP7WYs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Dense(60, input_dim=60, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqR4czCO7h5W",
        "colab_type": "code",
        "outputId": "8dcab1f1-c5d3-47e0-a075-590c7041e134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "model.fit(x=X_train,\n",
        "          y=y_train,\n",
        "          epochs=100,\n",
        "          batch_size=5,\n",
        "          verbose=1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.6483\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4809 - accuracy: 0.7862\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4124 - accuracy: 0.8207\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3583 - accuracy: 0.8690\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8897\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2782 - accuracy: 0.9103\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2510 - accuracy: 0.9310\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.9448\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2000 - accuracy: 0.9517\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9586\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.9724\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1444 - accuracy: 0.9724\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1313 - accuracy: 0.9862\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1193 - accuracy: 0.9862\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9793\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9862\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0898 - accuracy: 0.9931\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0744 - accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0629 - accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 1.0000\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0526 - accuracy: 1.0000\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 1.0000\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0454 - accuracy: 1.0000\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0418 - accuracy: 1.0000\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 1.0000\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 1.0000\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0327 - accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 1.0000\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0268 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0252 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0232 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0219 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0206 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0192 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0181 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0143 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0123 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0117 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0105 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0100 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0095 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0088 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0072 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0070 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0031 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0029 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0026 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0025 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0022 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0021 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0019 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0018 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0017 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd396099c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pImPGFE37iqF",
        "colab_type": "code",
        "outputId": "93b2f99c-f03e-4749-f29f-6de69d8e62a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "\n",
        "model_loss.plot()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd395ef1588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KvA557c9FHm",
        "colab_type": "text"
      },
      "source": [
        "## Model 3 : Evaluate a Smaller Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52pcP94i9eVb",
        "colab_type": "text"
      },
      "source": [
        "#### Example method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQIUWFA78bMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# smaller model\n",
        "def create_smaller():\n",
        "\n",
        "\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\tmodel.add(Dense(30, input_dim=60, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " \n",
        " \n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCxn-iPP9R79",
        "colab_type": "code",
        "outputId": "1cb36932-9b6c-411a-87e9-b7d84ec5b3db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "estimators = []\n",
        "\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=5, verbose=0)))\n",
        "\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "results = cross_val_score(pipeline, x, y, cv=kfold)\n",
        "\n",
        "print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smaller: 87.50% (5.31%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFAgrX859hFy",
        "colab_type": "text"
      },
      "source": [
        "#### My method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9XH2wg70-VAW",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iS2IhiWF-VAk",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "plVByCvk-VAs",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TJ8t5KV4-VA0",
        "colab": {}
      },
      "source": [
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3mI2YAvD-VA5",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Dense(30, input_dim=60, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "\n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "414bb2fc-d954-45a0-dc7e-72c28c3b5b63",
        "id": "9N5jjgk6-VBA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x=X_train,\n",
        "          y=y_train,\n",
        "          epochs=100,\n",
        "          batch_size=5,\n",
        "          verbose=1)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.7444 - accuracy: 0.4897\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.5664 - accuracy: 0.7103\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.8069\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.4273 - accuracy: 0.8345\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3829 - accuracy: 0.8552\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3472 - accuracy: 0.8690\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.8897\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2893 - accuracy: 0.8966\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2659 - accuracy: 0.9241\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2470 - accuracy: 0.9379\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2253 - accuracy: 0.9793\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.9793\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.1937 - accuracy: 0.9724\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1788 - accuracy: 0.9793\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1662 - accuracy: 0.9862\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1542 - accuracy: 0.9862\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1439 - accuracy: 0.9862\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.9862\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.9862\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1160 - accuracy: 0.9931\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1090 - accuracy: 0.9931\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.1014 - accuracy: 0.9931\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0948 - accuracy: 0.9931\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.9931\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0834 - accuracy: 0.9931\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0775 - accuracy: 0.9931\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0718 - accuracy: 0.9931\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9931\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9931\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9931\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0556 - accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0523 - accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0489 - accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0463 - accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0434 - accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0411 - accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0386 - accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0365 - accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0343 - accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0325 - accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0310 - accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0296 - accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0261 - accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0251 - accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0227 - accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0216 - accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0203 - accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0197 - accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0185 - accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0161 - accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0154 - accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0148 - accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0142 - accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0136 - accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0131 - accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0121 - accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0115 - accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0107 - accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0103 - accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0099 - accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0096 - accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0092 - accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0083 - accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0080 - accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0077 - accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0067 - accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0065 - accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0061 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0057 - accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd39664f128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "0988f849-4a88-4ebf-9f45-14cc41162df6",
        "id": "7Zc9sAg3-VBI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "\n",
        "model_loss.plot()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd397806a20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8cKOVUq-n_b",
        "colab_type": "text"
      },
      "source": [
        "## Model 4 : Evaluate a Larger Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z6nJpMk--E5",
        "colab_type": "text"
      },
      "source": [
        "#### Example method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7EdLywo-mKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# larger model\n",
        "def create_larger():\n",
        "\n",
        "\n",
        "\t# create model\n",
        "\tmodel = Sequential()\n",
        " \n",
        "\tmodel.add(Dense(60, input_dim=60, activation='relu'))\n",
        "\tmodel.add(Dense(30, activation='relu'))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        "\n",
        "\t# Compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " \n",
        "\n",
        "\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uBNte6R8-2Wf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimators = []\n",
        "\n",
        "estimators.append(('standardize', StandardScaler()))\n",
        "estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=5, verbose=0)))\n",
        "\n",
        "pipeline = Pipeline(estimators)\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
        "\n",
        "\n",
        "results = cross_val_score(pipeline, x, y, cv=kfold)\n",
        "\n",
        "print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5HpcaKw-9Vy",
        "colab_type": "text"
      },
      "source": [
        "#### My method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Lsr8rHDl_J6Y",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "43Gev-M6_J6o",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=101)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3f4uf4jT_J6-",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i1Tt72wV_J7M",
        "colab": {}
      },
      "source": [
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5gVppkUU_J7T",
        "colab": {}
      },
      "source": [
        "# create model\n",
        "model = Sequential()\n",
        " \n",
        "model.add(Dense(60, input_dim=60, activation='relu'))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        " \n",
        " \n",
        "# Compile model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WPrD0kwD_J7a",
        "colab": {}
      },
      "source": [
        "a = model.fit(x=X_train,\n",
        "          y=y_train,\n",
        "          epochs=100,\n",
        "          batch_size=5,\n",
        "          verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WQNC369M_J7g",
        "colab": {}
      },
      "source": [
        "model_loss = pd.DataFrame(model.history.history)\n",
        "\n",
        "model_loss.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgCuQ4jH_STd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w962v3yeOwb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}